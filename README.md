# Project info
**Prikupljanje podataka**

Prije provođenja ispitivanja, ispitanici su potpisali privolu u kojoj pristaju da se njihovi podaci koriste u svrhe ovog istraživanja. Ispitivanje je provedeno u laboratoriju, te se svaki od 20 ispitanika nalazio na jednakoj udaljenosti od kamere s jednakim osvjetljenjem. Cilj ispitivanja bio je postići vidnu razliku kod izraza lica ispitanika u opuštenom i stresiranom stanju. Kako bi željena reakcija bila postignuta, predstavljena su dva videozapisa u trajanju od 2.5 min. Namjena prvog videouratka bila je induciranje opuštenog stanja, što se ostvaruje prikazom prizora iz prirode uz opuštajuće pozadinske zvukove, pri čemu ispitanici nisu imali zadan zadatak.  
Drugi videozapis namijenjen je induciranju stresa. Od ispitanika se tražilo da verbalno odgovaraju na pitanja sa standardiziranog IQ testa, uz nedovoljnu količinu vremena za razmišljanje. Između dva videouratka, ispitanici su imali pauzu od 10 sekundi.
Rezultati su zapisani, te je provjereno dolazi li do velikih odstupanja, kako se ne bi narušio legitimitet ispitivanja. Rezultati ispitivanja prikazani su grafički, detaljnije u notebook i xslx fileovima na githubu. (github:ExperimentCheck & RezultatiIspitivanja).
(Prilikom snimanja jednog od videa došlo je do tehničkih poteškoća pa na kraju imamo 19 videja jedne skupine i 20 druge, ali tu ćemo raspisivati kao da je 20 u obe).

**Obrada podataka**

Prikupljeni videi podijeljeni su u dvije skupine, StressVideos i NonStressVideos, prva skupina su videi snimani tijekom gledanja relaksirajućeg filmića, dok se druga skupina sastoji od videouratka snimljenih tijekom rješavanja IQ testa. Videji obe skupine procesuirani su na isti način. Prvo, svi videji iz skupine spojeni su u jedan mp4 video file, zatim je taj video rascjepkan po intervalima od 10 sekundi (prema times.txt fileu). Na taj način dobiveno je 300 videa po skupini (duljina videa 150 sec puta 20 ispitanika djeljeno 10 sec), ili 15 videa po ispitaniku (github: VideoSequencing). 
Zatim, razvijena je petlja koja se vrti onoliko puta koliko ima videa u skupini, pri svakom krugu kreira folder koji odgovara rednom broju videa na koji je petlja ''došla''. U taj folder sprema izrezane izraze lica ispitanika pri svakom frameu videa ( videji traju po 10 sec, snimano je na 30 fps, lice je prisutno na svakom frameu, znaci svaki folder se sastoji od 300 izraza lica). Slijedi obrada spremljenih izraza lica; pomoću cv2 slike se iščitaju iz pripadajućeg foldera, iščitaju kao crno bijele, te se konvertiraju u numpy array i resizeaju u zadanu veličinu (50x50 pixela), numpy array se zatim sprema u pickle, te tu petlja zavrsava i kreće na idući video. Znači, jedan prolaz petlje kreira folder, napuni folder izrazima lica te obradi slike i spremi ih u pickle. Postoje dvije ovakve petlje, jedna za skupinu stresnih i jedna za skupinu nestresnih videa. Dakle, na 20 ispitanika imamo 300 videja, što daje 300 foldera sa po 300 izraza lica za svaku skupinu, znači 180000 jpg-ova. (github: FacesExtraction).
Zatim, kako bi dobili bolji skup podataka za učenje mreže, odlučili smo iskoristiti postojeći dataset FER2013, koji je javno dostupan na Kaggleu. FER2013 je set podataka za raspoznavanje izraza lica, sastoji se od 7 kategorija; angry, disgust, fear, happy, sad, surprise i neutral. Modificirali smo ga tako što smo kategoriju neutral nazvali expressionless, a ostale kategorije spojili i nazvali expressive. Te podatke smo zatim obradili tako da smo ih prebacili u crno bijele 50x50 pixela slike te konvertirali u numpy arrayeve i saveali u pickle ( github: ModifiedFER2013Dataset).
Sljedeće na redu bila je izgradnja našeg seta podataka. Pomoću podataka iz modificiranog FER2013 dataseta istrenirana je konvolucijska neuronska mreža za binarnu klasifikaciju. Na taj način, koristeći taj model možemo dobiti kolika je vjerojatnost da je neka slika ekspresivna ili neekspresivna. Logika iza ovog je sljedeća; prilikom prikupljanja i obrade naših podataka dobili smo velik broj slika, naša petlja je iz svakog framea videa vadila po jednu sliku, što odgovara 30 izraza lica po sekundi, a to naravno znači da je velik broj tih izraca lica gotovo identičan. Da smo toliku količinu sličnih podataka direktno iskoristili za treniranje mreže, mreža ne bi pravilno učila. Zato smo odlučili iskoristiti model binarne klasifikacije dobiven iz FER2013 dataseta.
Razvijena je petlja koja prolazi kroz svaki video iz skupine. Prvo se loada pickle file (Dobiven u FacesExtraction) koji odgovara broju videa na kojem je petlja. Pickle fali sastoji se od 300 np arrayeva slika, nakon što se loada, ubaci se u model binarne klasifikacije koji daje za svaku sliku vjerojatnost između 0 i 1, gdje 0 označava neekspresivnost, a 1 ekspresivnost. Sada svaka slika ima svoju pridruženu vjerojatnost, sljedeće smo odlučili izabrati 30 najekspresivnijih slika i 2 najneekspresivnije. To smo napravil tako da smo sortirali slike po njihovim vjerojatnostima, međutim, umjesto vjerojatnosti dan je niz indeksa koji pripadaju tim vjerojatnostima. Sada se unutar petlje dodaje još jedna petlja, koja za svaki indeks određen po vjerojatnostima nalazi sliku kojoj pripada isti taj indeks, tu sliku provučemo kroz cv2 i spremimo kao jpg. Postoje dvije ovakve petlje, petlja za ekspresivne slike vrti se 30 puta (broj indeksa), dok se petlja za neekspresivne vrti 2 puta (broj indeksa). Ovaj cijeli postupak ponavlja se za svaki video, te se onda ponavlja i za svaki video druge skupine videa. Na ovaj način imamo 9600 slika za svaku kategoriju i tako smo dobili naš set podataka. (github: BuildingDataset).
Sljedeće, morali smo obraditi naše podatke, napravljen je data directory StressDetection/Train te unutar njega dvije kategorije, nonstressed i stressed. Podaci su dalje obrađeni analogno onima iz modificranog FER2013 dataseta (github: StressDetectionData)
Zadnji korak je bio napraviti konvolucijsku neuronsku mrežu, istrenirati je i testirati. Prvo smo iz naših podataka stavili 20 posto sa strane za testiranje. Znači, 80 posto se koristi za treniranje mreže, a 20 za testiranje. Od podataka za treniranje 20 posto smo uzeli za validaciju. (nećemo sad ulaziti u arhitekturu mreže jer ćemo to još sigurno mijenjati). Mreža je istrenirana na train podacima te su rezultati kasnije evaluirani test podacima (github: NN).
